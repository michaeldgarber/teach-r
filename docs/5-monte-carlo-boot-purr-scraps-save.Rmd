#5-boot-monte-carlo scraps
For example, suppose, in an analysis, we

~/Dropbox/Work/teach/teach-r/docs/5-monte-carlo-boot-purrr.Rmd
In practice, we might apply Monte Carlo simulation in a scenario like that of a previous module, where we estimated the population living in a subâ€“set of a census tract and then estimated a characteristic of that population (e.g., household income) in that subset. Monte Carlo simulations are useful in such a scenario because both the population total and the household income are random variables

Suppose we have 

Solving statistics problems using repeated (re)sampling and a computer program has at least two important benefits: 1. It forces the analyst to identify each step of 2. It may avoid certain simplifying assumptions that may otherwise be imposed when uncertainty depends on the involvement of two or more variables. For example, suppose we aim to estimate a risk ratio: the risk of a disease in one population compared with that of another. We do not know e measure the impact of air pollution on asthma incidence. requently, measures of interest (say, a risk ratio) are themselves calculated from a sequence of steps, and each step may itself have uncertainty. For example, there may be uncertainty in measurement or uncertainty due to sampling.

in .both methods that rely on repeated sampling to estimate uncertainty of results from a statistical analysis. The repeated sampling in both methods

are similar in that they can both be used to estimate uncertainty of can both be used to estimate uncertainty in analysesare both ways to estimate variability in an analysis using computationrelated in that they are both ways to take advantage of computers to solve statistical problems.

Monte Carlo simulations can be used to estimate variability around a parameter's estimate. They are particularly useful when a parameter estimate is calculated based on several steps, and each step has variability.

Conventionally, under a Monte Carlo simulation, we either have some some pre-existing knowledge of or can make a reasonable guess of the distribution of the estimates in some of the preceding steps. For example, we might obtain a risk ratio from a meta-analysis, and that meta-analysis probably reports a confidence interval. Alternatively, if we're using census data, margins of error are typically reported.

suppose, for example, we estimate the effect of reducing air quality

Under a Monte Carlo simulation, suppose you make a reasonable guess about the distribution of each of your parameters individually, but estimating the distribution of a measure that depends on all three of those parameters may be challenging.

This is called a Monte Carlo simulation. In essence, rather than using math to derive solutions, we can use the computer to simulate repeated iterations of the analysis, randomly varying certain parameters according to our expectations at that step, and summarize the result.

#Bootstrapping
#Some theory:
#https://online.stat.psu.edu/stat500/book/export/html/618
#Try to estimate 

#note whether it's called a monte-carlo simulation or a bootstrap might be semantics
#https://en.wikipedia.org/wiki/Monte_Carlo_method
#Theoretical example first

#For my purposes here, I'm less concerned about precisely naming our statistical technique
#(bootstrapping vs Monte-Carlo simulations).
#I think they are both valuable tools to learn and they have lots of overlap in general concept.

#My goal here is to illustrate
#Applied example using ACS data
#Going back to our basic multiplication of variance formula.
#An alternative way to estimate the variance of two random variables is
#to use the Delta Method. In my opinion, bootstrapping is both simpler in that it requires
#less advanced math, and I find it conceptually appealing because you can watch what varies

#Possible extensions:
#Nested or multi-level bootstrapping. For example, groups might be sampled,
#and then, within group, individuals within group are sampled.

