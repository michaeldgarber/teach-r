<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Michael D Garber" />

<meta name="date" content="2022-08-23" />

<title>Monte Carlo Simulations and Bootstrapping and using purrr::map_dfr()</title>

<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>





<style type="text/css">
/* for pandoc --citeproc since 2.11 */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.tab('show');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html"></a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="https://michaeldgarber.github.io/">
    <span class="fa fa-home"></span>
     
    MDG
  </a>
</li>
<li>
  <a href="index.html">R course</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Monte Carlo Simulations and Bootstrapping and using purrr::map_dfr()</h1>
<h4 class="author">Michael D Garber</h4>
<h4 class="date">2022-08-23</h4>

</div>


<div class="figure">
<img src="images/chevy-monte-carlo-pic.jpg" width="500" alt="" />
<p class="caption">source: <a href="https://commons.wikimedia.org/wiki/File:Wiki79.jpg" class="uri">https://commons.wikimedia.org/wiki/File:Wiki79.jpg</a></p>
</div>
<div id="learning-objectives" class="section level1" number="1">
<h1><span class="header-section-number">1</span> Learning objectives</h1>
<ul>
<li><p>Provide a working definition of Monte Carlo simulations and bootstrapping</p></li>
<li><p>Perform a simple version of each using R</p></li>
</ul>
</div>
<div id="motivation" class="section level1" number="2">
<h1><span class="header-section-number">2</span> Motivation</h1>
<div id="sources-of-uncertainty-from-multiple-sources" class="section level2" number="2.1">
<h2><span class="header-section-number">2.1</span> Sources of uncertainty from multiple sources</h2>
<p>Almost any epidemiological or statistical analysis has uncertainty. Uncertainty may arise within the dataset available for analysis (the sample) or, if we aim to infer characteristics of a larger population from the sample, from sampling. For example, suppose we want to estimate the prevalence of Covid-19 in a county. To do so, we randomly sample 1,000 people from that county and test them using at-home antigen tests. Home tests have good specificity but fairly poor sensitivity,<span class="citation"><sup><a href="#ref-chu2022" role="doc-biblioref">1</a></sup></span> meaning some of the negative results probably were truly positive (false negative). And because the poor sensitivity is a property of the test, not the sampling, this error is expected to occur regardless of the sample size. In addition to this systematic error in measurement, uncertainty arises from the sampling because we don’t know if the Covid prevalence among the 1,000 people we tested represent that of the county. By chance, we could have tested a particularly healthy or sick sample.</p>
<p>In our final estimate of prevalence, how would we go about summarizing its uncertainty, considering both the expected error in measurement and random error from sampling? Statistics of course has fundamental methods for estimating uncertainty from multiple sources, but many traditional methods involve complex math.<span class="citation"><sup><a href="#ref-distribu2022a" role="doc-biblioref">2</a></sup></span> To simplify the math, analysts often make assumptions that may not hold, for example that random variables considered in the analysis are independent from one another. In this particular example, the two sources of uncertainty (test accuracy and sampling) are actually probably independent from one another, but that independence often does not hold.</p>
</div>
<div id="when-independence-between-sources-of-uncertainty-does-not-hold" class="section level2" number="2.2">
<h2><span class="header-section-number">2.2</span> When independence between sources of uncertainty does not hold</h2>
<p>For example, in my dissertation, I aimed to estimate the total amount of bicycling on every road in Atlanta. I had two sources of information, both of which had uncertainty. The first was a sample of bicycling on every roadway obtained from a smartphone app, inducing sampling variability and probably other sources of bias.<span class="citation"><sup><a href="#ref-garber2022" role="doc-biblioref">3</a></sup></span> The second was a set of about 15 bicycle counters located throughout the city, assumed to accurately measure all bicycling. I used these counters to estimate the proportion of bicyclists captured by the app. In this analysis, bike traffic in the smartphone-generated sample was correlated with the proportion captured in the app over the counter locations, meaning estimating the variance of their product would require me to consider this correlation. Accurately estimating the variance arising from both of these inter-related sources by appropriately considering their covariance using traditional pen-and-paper statistical methods, and propagating that combined uncertainty through other steps in the analysis which may themselves have uncertainty, would be difficult.</p>
</div>
</div>
<div id="estimating-variability-via-repeated-resampling-of-random-variations" class="section level1" number="3">
<h1><span class="header-section-number">3</span> Estimating variability via repeated (re)sampling of random variations</h1>
<p>Fortunately, we can estimate uncertainty using the computer which largely obviates the need to do complex math. Two broad (and, depending on the definition, overlapping) ways to estimate uncertainty using computer-based simulation techniques are <strong>Monte Carlo simulations</strong> and <strong>bootstrapping</strong>. In addition to easing the math, these simulation methods can help the analyst visualize how and when something varies in the analysis, which facilitates clarity and understanding.</p>
<div id="monte-carlo-simulations" class="section level2" number="3.1">
<h2><span class="header-section-number">3.1</span> Monte Carlo simulations</h2>
<blockquote>
<p>“Monte Carlo simulation is a method of analysis based on artificially recreating a chance process (usually with a computer), running it many times, and directly observing the results.”</p>
</blockquote>
<p>An important aspect of a traditional Monte Carlo simulation is that the distribution (i.e., its mean and variance) of each individual source of uncertainty is specified by the analyst. It is not estimated from the data. Monte Carlo simulations are useful to propagate multiple sources of variation throughout an analysis pipeline to assess the impact of all sources of uncertainty on the final result. And, as noted, they’re especially helpful compared with traditional (non-computer-based) statistical methods when those sources of variation are correlated with one another.</p>
</div>
<div id="bootstrapping" class="section level2" number="3.2">
<h2><span class="header-section-number">3.2</span> Bootstrapping</h2>
<p>Monte Carlo simulation in its typical implementation cannot, however, directly estimate the sampling distribution. But bootstrapping can.</p>
<blockquote>
<p>In statistics…, bootstrapping has come to mean to resampling [with replacement] repeatedly and randomly from an original, initial sample using each bootstrapped sample to compute a statistic. The resulting empirical distribution of the statistic is then examined and interpreted as an approximation to the true sampling distribution.</p>
</blockquote>
<p>The bootstrap was introduced by Brad Efron in the late 1970s. There are many forms of bootstrapping, including ways to bootstrap residuals from regression models.<span class="citation"><sup><a href="#ref-efron2016" role="doc-biblioref">4</a></sup></span> The most essential is simply re-sampling entire observations from the sample, summarizing each new sample, and using the distribution of those summary statistics to infer the sampling distribution.</p>
<p>It is certainly similar to Monte Carlo techniques and might be viewed as a subset thereof. The key difference is that the bootstrap estimates a distribution using data we have, and the Monte Carlo technique described above</p>
</div>
</div>
<div id="example-code-for-each-method-using-purrrmap_dfr" class="section level1" number="4">
<h1><span class="header-section-number">4</span> Example code for each method using <code>purrr::map_dfr()</code></h1>
<div id="monte-carlo-simulation" class="section level2" number="4.1">
<h2><span class="header-section-number">4.1</span> Monte Carlo simulation</h2>
<p>Suppose we have a state with 100 counties. We simulate one single dataset, specifying that the mean county population is 1,000 and the probability of the a demographic variable (dem) is 0.5. The prevalence (<code>prev</code>)depends in part on pop and dem, and the number of cases in the county is estimated from pop and prev.</p>
<pre class="r"><code>library(tidyverse)
library(truncnorm)
set.seed(11)#set the seed so this dataset is always the same.
monte_carlo_sim_frozen = 1:100 %&gt;% 
  as_tibble() %&gt;% 
  rename(county_id = value) %&gt;% 
  mutate(
    state = 1,
    pop = rpois(n=n(), lambda=10000), #mean = var=1000
    dem = rbinom(n=n(), size=1, prob =.5),
    prev = rtruncnorm(
      n=n(), 
      a=0, 
      b=1,
      mean=.2+(pop/100000)+(dem/10),
      sd=0.05),
    n_cases = as.integer(pop*prev),
  )

monte_carlo_sim_frozen</code></pre>
<pre><code>## # A tibble: 100 × 6
##    county_id state   pop   dem  prev n_cases
##        &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt;   &lt;int&gt;
##  1         1     1  9940     1 0.457    4541
##  2         2     1  9780     1 0.442    4321
##  3         3     1  9863     1 0.457    4504
##  4         4     1  9884     0 0.294    2905
##  5         5     1 10132     0 0.297    3005
##  6         6     1 10062     1 0.434    4367
##  7         7     1  9995     0 0.264    2635
##  8         8     1  9995     1 0.514    5134
##  9         9     1  9965     0 0.286    2853
## 10        10     1  9995     0 0.281    2804
## # … with 90 more rows
## # ℹ Use `print(n = ...)` to see more rows</code></pre>
<p>What is the mean and standard deviation number of cases per county?</p>
<pre class="r"><code>monte_carlo_sim_frozen %&gt;% 
  group_by(state) %&gt;% 
  summarise(
    n_cases_mean = mean(n_cases),
    n_cases_sd = sd(n_cases))</code></pre>
<pre><code>## # A tibble: 1 × 3
##   state n_cases_mean n_cases_sd
##   &lt;dbl&gt;        &lt;dbl&gt;      &lt;dbl&gt;
## 1     1        3512.       736.</code></pre>
<div id="define-a-function-for-replications" class="section level3" number="4.1.1">
<h3><span class="header-section-number">4.1.1</span> Define a function for replications</h3>
<p>Now let’s randomly vary some things based on the frozen dataset. That dataset itself was created randomly, but let’s pretend that it is frozen and not changing now. In this code, we will create a function that will create new variables that will change.</p>
<p>Create a function for the creation of this dataset, run it 500 times, and find the mean of the means over those 500 iterations. The argument for this function is <code>rep_id_val</code>. I create a new variable called <code>rep_id</code>, and in each iteration, that variable takes <code>rep_id_val</code>.</p>
<pre class="r"><code>monte_carlo_sim_fun = function(rep_id_val){
  monte_carlo_sim_df = 1:100 %&gt;% 
    as_tibble() %&gt;% 
    rename(county_id = value) %&gt;% 
    mutate(
      state = 1,
      pop = rpois(n=n(), lambda=10000), #mean = var=1000
      dem = rbinom(n=n(), size=1, prob =.5),
      prev = rtruncnorm(
        n=n(), 
        a=0, 
        b=1,
        mean=.2+(pop/100000)+(dem/10),
        sd=0.05+(pop/400000)+(dem/40)),
    n_cases = as.integer(pop*prev),
    rep_id = rep_id_val  #add replication ID
  )
}</code></pre>
<p>Define the number of replications. We are creating an integer vector to be iterated through.</p>
<pre class="r"><code>rep_id_val_list = 1:500
class(rep_id_val_list)</code></pre>
<pre><code>## [1] &quot;integer&quot;</code></pre>
</div>
<div id="run-the-replications" class="section level3" number="4.1.2">
<h3><span class="header-section-number">4.1.2</span> Run the replications</h3>
<p>Simulate 500 versions of this state, each time generating new counties randomly varying according to the distribution above. We use <code>map_dfr()</code> from the purrr package to run th code and then stack the results on top of one another. Note the unusual structure of this code. The function we created above, <code>monte_carlo_sim_fun(),</code> is inside <code>map_dfr()</code>, and the list of replication ids, <code>rep_id_val_list,</code> begins the pipe sequence.</p>
<pre class="r"><code>library(purrr) #make sure it&#39;s attached
set.seed(NULL) #allow it to vary differently each time.
monte_carlo_sim_lots  = rep_id_val_list %&gt;% 
  map_dfr(monte_carlo_sim_fun) </code></pre>
<p>Take a look at output.</p>
<pre class="r"><code>monte_carlo_sim_lots</code></pre>
<pre><code>## # A tibble: 50,000 × 7
##    county_id state   pop   dem  prev n_cases rep_id
##        &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt;   &lt;int&gt;  &lt;int&gt;
##  1         1     1 10091     0 0.262    2646      1
##  2         2     1 10125     1 0.562    5691      1
##  3         3     1 10131     0 0.306    3104      1
##  4         4     1  9975     0 0.205    2049      1
##  5         5     1  9982     0 0.277    2762      1
##  6         6     1  9951     1 0.456    4542      1
##  7         7     1  9903     0 0.336    3327      1
##  8         8     1  9975     0 0.245    2444      1
##  9         9     1  9949     0 0.288    2863      1
## 10        10     1 10013     1 0.451    4514      1
## # … with 49,990 more rows
## # ℹ Use `print(n = ...)` to see more rows</code></pre>
<p>How many rows?</p>
<pre class="r"><code>nrow(monte_carlo_sim_lots)</code></pre>
<pre><code>## [1] 50000</code></pre>
<p>How many distinct values of <code>rep_id</code>?</p>
<pre class="r"><code>n_distinct(monte_carlo_sim_lots$rep_id)</code></pre>
<pre><code>## [1] 500</code></pre>
</div>
<div id="summarize-results" class="section level3" number="4.1.3">
<h3><span class="header-section-number">4.1.3</span> Summarize results</h3>
<p>What’s the distribution of <code>n_cases_mean</code> over Monte Carlo replications?</p>
<pre class="r"><code>monte_carlo_sim_lots %&gt;% 
  group_by(rep_id,state) %&gt;% 
  summarise(
    n_cases_mean = mean(n_cases),
    n_cases_sd = sd(n_cases)) %&gt;% 
  ggplot(aes( n_cases_mean))+
  geom_histogram()</code></pre>
<pre><code>## `summarise()` has grouped output by &#39;rep_id&#39;. You can override using the
## `.groups` argument.
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="boot-monte-carlo-purrr_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<p>What is the 2.5th, 50th (median), and 97.5th percentile of the mean number of cases for each county? This could be used to report a confidence interval around the estimated median number of cases.</p>
<pre class="r"><code>monte_carlo_sim_lots %&gt;% 
  group_by(rep_id,state) %&gt;% #group by both rep id and state
  summarise(
    n_cases_mean = mean(n_cases),
    n_cases_sd = sd(n_cases)) %&gt;% 
  group_by(state) %&gt;% #now collapse over rep id
  summarise(
    n_cases_mean_ll = quantile(n_cases_mean, probs = 0.025, na.rm=TRUE),
    n_cases_mean_med = quantile(n_cases_mean, probs = 0.5, na.rm=TRUE),
    n_cases_mean_ul = quantile(n_cases_mean, probs = 0.975, na.rm=TRUE)
    ) %&gt;% 
  ungroup()</code></pre>
<pre><code>## `summarise()` has grouped output by &#39;rep_id&#39;. You can override using the
## `.groups` argument.</code></pre>
<pre><code>## # A tibble: 1 × 4
##   state n_cases_mean_ll n_cases_mean_med n_cases_mean_ul
##   &lt;dbl&gt;           &lt;dbl&gt;            &lt;dbl&gt;           &lt;dbl&gt;
## 1     1           3308.            3493.           3676.</code></pre>
</div>
</div>
<div id="bootstrap" class="section level2" number="4.2">
<h2><span class="header-section-number">4.2</span> Bootstrap</h2>
<p>Now let’s bootstrap <code>monte_carlo_sim_frozen</code>, again supposing that even though it was generated randomly, it is now frozen in sample and can be viewed as a single sample. We will then re-sample it <strong>with replacement</strong> with sampling probability of 1, meaning all rows will be re-sampled. This means that, in a given sample, some counties will repeat, and some will not appear at all.</p>
<p>Here’s one example:</p>
<pre class="r"><code>monte_carlo_sim_one_boot = monte_carlo_sim_frozen %&gt;% 
  slice_sample(prop=1,replace=TRUE)</code></pre>
<p>Take a look:</p>
<pre class="r"><code>monte_carlo_sim_one_boot</code></pre>
<pre><code>## # A tibble: 100 × 6
##    county_id state   pop   dem  prev n_cases
##        &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt;   &lt;int&gt;
##  1        90     1  9986     1 0.315    3145
##  2        39     1  9977     1 0.376    3748
##  3        71     1  9944     1 0.424    4215
##  4        92     1 10015     1 0.385    3852
##  5        63     1  9934     0 0.340    3375
##  6        79     1 10059     0 0.273    2747
##  7        72     1 10051     0 0.216    2172
##  8        53     1 10075     1 0.369    3722
##  9        87     1 10139     1 0.340    3449
## 10       100     1 10128     1 0.349    3539
## # … with 90 more rows
## # ℹ Use `print(n = ...)` to see more rows</code></pre>
<p>As expected, we have the same number of rows, but fewer unique values for <code>county_id.</code> Some are repeating.</p>
<pre class="r"><code>nrow(monte_carlo_sim_one_boot)</code></pre>
<pre><code>## [1] 100</code></pre>
<pre class="r"><code>n_distinct(monte_carlo_sim_one_boot$county_id)</code></pre>
<pre><code>## [1] 64</code></pre>
<p>Repeat this bootstrap procedure 500 times by first writing a function and then iterating replications through that function using <code>purrr::map_dfr()</code></p>
<div id="define-a-function-for-replications-1" class="section level3" number="4.2.1">
<h3><span class="header-section-number">4.2.1</span> Define a function for replications</h3>
<pre class="r"><code>boot_fun = function(rep_id_val){
  monte_carlo_sim_boot = monte_carlo_sim_frozen %&gt;% 
    slice_sample(prop=1,replace=TRUE) %&gt;% 
    mutate(rep_id = rep_id_val) #to keep track of reps
}</code></pre>
</div>
<div id="run-the-replications-1" class="section level3" number="4.2.2">
<h3><span class="header-section-number">4.2.2</span> Run the replications</h3>
<p>Simulate 500 versions of this state, each time generating new counties randomly varying according to the distribution above. We use <code>map_dfr()</code> from the purrr package to run the function and then stack the results on top of one another. Note the unusual structure of this code. The function we created above, <code>monte_carlo_sim_fun(),</code> is inside <code>map_dfr()</code>, and the list of replication ids, <code>rep_id_val_list,</code> begins the pipe sequence.</p>
<pre class="r"><code>boot_lots  = rep_id_val_list %&gt;% 
  map_dfr(boot_fun) </code></pre>
</div>
<div id="summarize-results-1" class="section level3" number="4.2.3">
<h3><span class="header-section-number">4.2.3</span> Summarize results</h3>
<pre class="r"><code>boot_lots</code></pre>
<pre><code>## # A tibble: 50,000 × 7
##    county_id state   pop   dem  prev n_cases rep_id
##        &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt;   &lt;int&gt;  &lt;int&gt;
##  1        60     1 10036     0 0.294    2947      1
##  2        42     1 10054     1 0.350    3516      1
##  3        81     1 10048     0 0.278    2795      1
##  4        70     1  9897     1 0.398    3936      1
##  5        99     1  9864     0 0.291    2868      1
##  6        97     1 10028     1 0.442    4434      1
##  7        69     1  9963     0 0.234    2334      1
##  8        83     1 10022     1 0.392    3931      1
##  9         5     1 10132     0 0.297    3005      1
## 10        25     1  9909     1 0.482    4773      1
## # … with 49,990 more rows
## # ℹ Use `print(n = ...)` to see more rows</code></pre>
<p>What’s the distribution of <code>n_cases_mean</code> over bootstrap replications?</p>
<pre class="r"><code>boot_lots %&gt;% 
  group_by(rep_id,state) %&gt;% 
  summarise(
    n_cases_mean = mean(n_cases),
    n_cases_sd = sd(n_cases)) %&gt;% 
  ggplot(aes( n_cases_mean))+
  geom_histogram()</code></pre>
<pre><code>## `summarise()` has grouped output by &#39;rep_id&#39;. You can override using the
## `.groups` argument.
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="boot-monte-carlo-purrr_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
<pre class="r"><code>boot_lots %&gt;% 
  group_by(rep_id,state) %&gt;% #group by both rep id and state
  summarise(
    n_cases_mean = mean(n_cases),
    n_cases_sd = sd(n_cases)) %&gt;% 
  group_by(state) %&gt;% #now collapse over rep id
  summarise(
    n_cases_mean_ll = quantile(n_cases_mean, probs = 0.025, na.rm=TRUE),
    n_cases_mean_med = quantile(n_cases_mean, probs = 0.5, na.rm=TRUE),
    n_cases_mean_ul = quantile(n_cases_mean, probs = 0.975, na.rm=TRUE)
    ) %&gt;% 
  ungroup()</code></pre>
<pre><code>## `summarise()` has grouped output by &#39;rep_id&#39;. You can override using the
## `.groups` argument.</code></pre>
<pre><code>## # A tibble: 1 × 4
##   state n_cases_mean_ll n_cases_mean_med n_cases_mean_ul
##   &lt;dbl&gt;           &lt;dbl&gt;            &lt;dbl&gt;           &lt;dbl&gt;
## 1     1           3359.            3507.           3647.</code></pre>
<p>Advantages of these computation-based simulation methods</p>
<ul>
<li><p>Makes explicit where the variation is coming from and aids in intuition.</p></li>
<li><p>Easily accommodates correlation between variables and avoids difficult math.</p></li>
</ul>
<p>Differences between the two:</p>
<p>Difference: Is variability specified by the user or is it estimated from the sample?</p>
<p>In common: Bootstrapping and Monte Carlo simulations both use repeated sampling to estimate uncertainty</p>
<p>Steps:</p>
<ol style="list-style-type: decimal">
<li>Define a function that contains steps of the analysis with variability.</li>
<li>Run that function lots of times using <code>purrr::map_dfr()</code></li>
<li>Summarize the distribution of the results. Conventionally, take the median, 2.5th, and 97.5th percentile.</li>
</ol>
</div>
</div>
</div>
<div id="references" class="section level1 unnumbered">
<h1><strong>References</strong></h1>
<div id="refs" class="references csl-bib-body">
<div id="ref-chu2022" class="csl-entry">
<div class="csl-left-margin">1. </div><div class="csl-right-inline">Chu VT, Schwartz NG, Donnelly MAP, et al. Comparison of Home Antigen Testing With RT-PCR and Viral Culture During the Course of SARS-CoV-2 Infection. <em>JAMA Internal Medicine</em>. Published online April 29, 2022. doi:<a href="https://doi.org/10.1001/jamainternmed.2022.1827">10.1001/jamainternmed.2022.1827</a></div>
</div>
<div id="ref-distribu2022a" class="csl-entry">
<div class="csl-left-margin">2. </div><div class="csl-right-inline">Distribution of the product of two random variables. Published online May 29, 2022. <a href="https://en.wikipedia.org/wiki/Distribution_of_the_product_of_two_random_variables">https://en.wikipedia.org/wiki/Distribution_of_the_product_of_two_random_variables</a></div>
</div>
<div id="ref-garber2022" class="csl-entry">
<div class="csl-left-margin">3. </div><div class="csl-right-inline">Garber MD, Flanders WD, Watkins KE, Lobelo RLF, Kramer MR, McCullough LE. Have paved trails and protected bike lanes led to more bicycling in atlanta? A generalized synthetic-control analysis. <em>Epidemiology</em>. 2022;33(4):493-504. doi:<a href="https://doi.org/10.1097/EDE.0000000000001483">10.1097/EDE.0000000000001483</a></div>
</div>
<div id="ref-efron2016" class="csl-entry">
<div class="csl-left-margin">4. </div><div class="csl-right-inline">Efron B, Hastie T. <em>Computer Age Statistical Inference: Algorithms, Evidence, and Data Science</em>. Cambridge University Press; 2016.</div>
</div>
</div>
</div>

<br>
<br>
<p>Copyright &copy; 2022 Michael D. Garber </p>


</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3,h4",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
